{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "authorship_tag": "ABX9TyMG2nYPt0MENwtnYx+9QODy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yonad91/-Plant-Disease-Detection/blob/main/PlantDiseaseDetection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhZ0YwZJtq02"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install tensorflow gradio kaggle -q\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import gradio as gr\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Constants / Paths\n",
        "# -------------------------\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "KAGGLE_DATASET = 'vipoooool/new-plant-diseases-dataset'  # Change dataset if desired\n",
        "WORK_DIR = '/content'\n",
        "DATASET_ROOT = os.path.join(WORK_DIR, 'New_Plant_Diseases_Dataset')\n",
        "TRAIN_DIR = os.path.join(DATASET_ROOT, 'train')\n",
        "VALID_DIR = os.path.join(DATASET_ROOT, 'valid')\n",
        "TEST_DIR = os.path.join(DATASET_ROOT, 'test')  # may or may not exist\n"
      ],
      "metadata": {
        "id": "1KVeG-UOtvgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 1: Upload kaggle.json and download dataset\n",
        "# -------------------------\n",
        "print(\"Step 1: Please browse and upload your 'kaggle.json' API token when prompted.\")\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise FileNotFoundError(\"kaggle.json not uploaded.\")\n",
        "    kaggle_json_filename = list(uploaded.keys())[0]\n",
        "    kaggle_json_path = os.path.join(WORK_DIR, kaggle_json_filename)\n",
        "\n",
        "    os.makedirs(os.path.expanduser('~/.kaggle'), exist_ok=True)\n",
        "    shutil.copy(kaggle_json_path, os.path.expanduser('~/.kaggle/kaggle.json'))\n",
        "    os.chmod(os.path.expanduser('~/.kaggle/kaggle.json'), 0o600)\n",
        "\n",
        "    print(\"Step 2: Kaggle API key successfully configured.\")\n",
        "    print(\"Step 3: Starting download of dataset...\")\n",
        "    os.system(f'kaggle datasets download -d {KAGGLE_DATASET} -p {WORK_DIR} --force')\n",
        "\n",
        "    zip_files = [f for f in os.listdir(WORK_DIR) if f.endswith('.zip')]\n",
        "    if not zip_files:\n",
        "        raise FileNotFoundError(\"Downloaded dataset ZIP file not found.\")\n",
        "\n",
        "    zip_path = os.path.join(WORK_DIR, zip_files[0])\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        z.extractall(WORK_DIR)\n",
        "\n",
        "    # Locate train folder in extracted dataset\n",
        "    def find_folder_with_subdir(root, target_subdir='train'):\n",
        "        for dirpath, dirnames, filenames in os.walk(root):\n",
        "            if target_subdir in dirnames:\n",
        "                return os.path.join(dirpath, target_subdir), dirpath\n",
        "        return None, None\n",
        "\n",
        "    train_found, parent = find_folder_with_subdir(WORK_DIR, 'train')\n",
        "    if train_found:\n",
        "        extracted_root = parent\n",
        "        try:\n",
        "            shutil.move(extracted_root, DATASET_ROOT)\n",
        "        except:\n",
        "            DATASET_ROOT = extracted_root\n",
        "        TRAIN_DIR = os.path.join(DATASET_ROOT, 'train')\n",
        "        VALID_DIR = os.path.join(DATASET_ROOT, 'valid')\n",
        "        TEST_DIR = os.path.join(DATASET_ROOT, 'test')\n",
        "\n",
        "        try: os.remove(zip_path)\n",
        "        except: pass\n",
        "\n",
        "        print(\"Dataset ready at:\", DATASET_ROOT)\n",
        "    else:\n",
        "        raise FileNotFoundError(\"Could not find 'train' folder in extracted dataset.\")\n",
        "\n",
        "except Exception as e:\n",
        "    raise RuntimeError(f\"Dataset download/extraction failed: {e}\")\n"
      ],
      "metadata": {
        "id": "vZ83FogQtvdM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 2: Create tf.data datasets from directories\n",
        "# -------------------------\n",
        "if not os.path.exists(TRAIN_DIR):\n",
        "    raise FileNotFoundError(f\"Training directory not found: {TRAIN_DIR}\")\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "def make_datasets(train_dir, valid_dir=None, test_dir=None, img_size=(224,224), batch_size=32):\n",
        "    if valid_dir and os.path.exists(valid_dir):\n",
        "        train_ds = image_dataset_from_directory(train_dir, labels='inferred', label_mode='int',\n",
        "                                                batch_size=batch_size, image_size=img_size, shuffle=True)\n",
        "        val_ds = image_dataset_from_directory(valid_dir, labels='inferred', label_mode='int',\n",
        "                                              batch_size=batch_size, image_size=img_size, shuffle=False)\n",
        "    else:\n",
        "        train_ds = image_dataset_from_directory(train_dir, labels='inferred', label_mode='int',\n",
        "                                                batch_size=batch_size, image_size=img_size, shuffle=True,\n",
        "                                                validation_split=0.15, subset='training', seed=123)\n",
        "        val_ds = image_dataset_from_directory(train_dir, labels='inferred', label_mode='int',\n",
        "                                              batch_size=batch_size, image_size=img_size, shuffle=False,\n",
        "                                              validation_split=0.15, subset='validation', seed=123)\n",
        "\n",
        "    if test_dir and os.path.exists(test_dir):\n",
        "        test_ds = image_dataset_from_directory(test_dir, labels='inferred', label_mode='int',\n",
        "                                               batch_size=batch_size, image_size=img_size, shuffle=False)\n",
        "    else:\n",
        "        test_ds = val_ds\n",
        "\n",
        "    normalization_layer = layers.Rescaling(1./255)\n",
        "    train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(AUTOTUNE)\n",
        "    val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(AUTOTUNE)\n",
        "    test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y)).prefetch(AUTOTUNE)\n",
        "    return train_ds, val_ds, test_ds\n",
        "\n",
        "train_ds, val_ds, test_ds = make_datasets(TRAIN_DIR, VALID_DIR, TEST_DIR, IMAGE_SIZE, BATCH_SIZE)\n",
        "\n",
        "try:\n",
        "    CLASS_NAMES = train_ds.class_names\n",
        "except:\n",
        "    CLASS_NAMES = sorted([d for d in os.listdir(TRAIN_DIR) if os.path.isdir(os.path.join(TRAIN_DIR, d))])\n",
        "NUM_CLASSES = len(CLASS_NAMES)\n",
        "print(\"Detected classes:\", NUM_CLASSES, CLASS_NAMES)\n"
      ],
      "metadata": {
        "id": "GI13Bamstval"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 3: Build VGG16 + custom head\n",
        "# -------------------------\n",
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n",
        "base_model.trainable = False\n",
        "\n",
        "model = models.Sequential([\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dense(256, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "UGLifIEatvYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 4: Train model\n",
        "# -------------------------\n",
        "EPOCHS = 10\n",
        "STEPS_PER_EPOCH = 1000\n",
        "VALIDATION_STEPS = math.ceil(tf.data.experimental.cardinality(val_ds).numpy())\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint('best_model_plant.h5', save_best_only=True, monitor='val_accuracy', verbose=1)\n",
        "reduce_lr_cb = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-8, verbose=1)\n",
        "csv_logger_cb = CSVLogger('training_log_plant.csv', append=False)\n",
        "\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH,\n",
        "    validation_steps=VALIDATION_STEPS,\n",
        "    callbacks=[checkpoint_cb, reduce_lr_cb, csv_logger_cb],\n",
        "    verbose=1\n",
        ")\n"
      ],
      "metadata": {
        "id": "gvpHYlBjtvVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 5: Plot and evaluate\n",
        "# -------------------------\n",
        "acc = history.history.get('accuracy', [])\n",
        "val_acc = history.history.get('val_accuracy', [])\n",
        "loss = history.history.get('loss', [])\n",
        "val_loss = history.history.get('val_loss', [])\n",
        "\n",
        "plt.figure(figsize=(12,5))\n",
        "plt.subplot(1,2,1); plt.plot(acc, label='Train Acc'); plt.plot(val_acc, label='Val Acc'); plt.legend(); plt.title('Accuracy')\n",
        "plt.subplot(1,2,2); plt.plot(loss, label='Train Loss'); plt.plot(val_loss, label='Val Loss'); plt.legend(); plt.title('Loss')\n",
        "plt.show()\n",
        "\n",
        "y_true, y_pred = [], []\n",
        "for imgs, labels in test_ds:\n",
        "    preds = model.predict(imgs)\n",
        "    y_true.extend(labels.numpy().tolist())\n",
        "    y_pred.extend(np.argmax(preds, axis=1).tolist())\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=CLASS_NAMES))\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(cm)\n"
      ],
      "metadata": {
        "id": "dSPCnZ5CtvM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------\n",
        "# Step 6: Save model and Gradio interface\n",
        "# -------------------------\n",
        "MODEL_FILENAME = \"plant_disease_vgg16_final.h5\"\n",
        "model.save(MODEL_FILENAME)\n",
        "print(f\"\\nModel saved as {MODEL_FILENAME}\")\n",
        "\n",
        "def predict_image_gradio(image: np.ndarray):\n",
        "    if image is None:\n",
        "        return \"No image\", \"\", \"\"\n",
        "    img = tf.image.resize(image, IMAGE_SIZE)\n",
        "    img = tf.expand_dims(img, 0) / 255.0\n",
        "    preds = model.predict(img)\n",
        "    idx = int(np.argmax(preds))\n",
        "    confidence = float(np.max(preds))\n",
        "    label = CLASS_NAMES[idx]\n",
        "    description = f\"Predicted class: {label}. Confidence: {confidence*100:.2f}%.\"\n",
        "    return label, f\"{confidence*100:.2f}%\", description\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=predict_image_gradio,\n",
        "    inputs=gr.Image(type=\"numpy\", label=\"Upload plant image\"),\n",
        "    outputs=[gr.Textbox(label=\"Prediction\"), gr.Textbox(label=\"Confidence\"), gr.Textbox(label=\"Notes\")],\n",
        "    title=\"Plant Disease Detection (VGG16 Transfer Learning)\",\n",
        "    description=\"Upload an image for inference.\"\n",
        ")\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "2LoaSC50t6M3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KwZZCo88t6Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qxy695kUt6IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sG_nduiyt6GE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}